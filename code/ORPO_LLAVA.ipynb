{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /venv/main/lib/python3.10/site-packages (4.53.2)\n",
      "Requirement already satisfied: trl in /venv/main/lib/python3.10/site-packages (0.19.1)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: huggingface_hub in /venv/main/lib/python3.10/site-packages (0.33.1)\n",
      "Requirement already satisfied: bitsandbytes in /venv/main/lib/python3.10/site-packages (0.46.1)\n",
      "Requirement already satisfied: wandb in /venv/main/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in /venv/main/lib/python3.10/site-packages (11.0.0)\n",
      "Requirement already satisfied: torchvision in /venv/main/lib/python3.10/site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: peft in /venv/main/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: ipywidgets in /venv/main/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: nbformat in /venv/main/lib/python3.10/site-packages (5.10.4)\n",
      "Collecting vllm\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "  Downloading vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /venv/main/lib/python3.10/site-packages (from trl) (1.8.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /venv/main/lib/python3.10/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /venv/main/lib/python3.10/site-packages (from trl) (1.8.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /venv/main/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /venv/main/lib/python3.10/site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /venv/main/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /venv/main/lib/python3.10/site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /venv/main/lib/python3.10/site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /venv/main/lib/python3.10/site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /venv/main/lib/python3.10/site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in /venv/main/lib/python3.10/site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (2.33.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /venv/main/lib/python3.10/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /venv/main/lib/python3.10/site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /venv/main/lib/python3.10/site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /venv/main/lib/python3.10/site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /venv/main/lib/python3.10/site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /venv/main/lib/python3.10/site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in /venv/main/lib/python3.10/site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (2.33.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /venv/main/lib/python3.10/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /venv/main/lib/python3.10/site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /venv/main/lib/python3.10/site-packages (from nbformat) (5.8.1)\n",
      "Collecting cachetools (from vllm)\n",
      "Collecting cachetools (from vllm)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting openai<=1.90.0,>=1.52.0 (from vllm)\n",
      "Collecting openai<=1.90.0,>=1.52.0 (from vllm)\n",
      "  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines==0.1.11 (from vllm)\n",
      "Collecting outlines==0.1.11 (from vllm)\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.19 (from vllm)\n",
      "Collecting xgrammar==0.1.19 (from vllm)\n",
      "  Downloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "  Downloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /venv/main/lib/python3.10/site-packages (from vllm) (27.0.0)\n",
      "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /venv/main/lib/python3.10/site-packages (from vllm) (27.0.0)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.6.2 (from mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading mistral_common-1.8.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mistral_common>=1.6.2 (from mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading mistral_common-1.8.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting einops (from vllm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting einops (from vllm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.10.2 (from vllm)\n",
      "Collecting compressed-tensors==0.10.2 (from vllm)\n",
      "  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm)\n",
      "Collecting depyf==0.18.0 (from vllm)\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm)\n",
      "Collecting watchfiles (from vllm)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting python-json-logger (from vllm)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting python-json-logger (from vllm)\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy (from vllm)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy (from vllm)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting pybase64 (from vllm)\n",
      "Collecting pybase64 (from vllm)\n",
      "  Downloading pybase64-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "  Downloading pybase64-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "  Downloading ray-2.47.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "  Downloading ray-2.47.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "INFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting vllm\n",
      "INFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.9.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting openai>=1.52.0 (from vllm)\n",
      "  Downloading vllm-0.9.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting openai>=1.52.0 (from vllm)\n",
      "  Downloading openai-1.96.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting compressed-tensors==0.10.1 (from vllm)\n",
      "  Downloading openai-1.96.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting compressed-tensors==0.10.1 (from vllm)\n",
      "  Downloading compressed_tensors-0.10.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading compressed_tensors-0.10.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp>=1.26.0 (from vllm)\n",
      "Collecting opentelemetry-exporter-otlp>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_exporter_otlp-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_exporter_otlp-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions-ai>=0.4.1 (from vllm)\n",
      "  Downloading opentelemetry_semantic_conventions_ai-0.4.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting vllm\n",
      "Collecting opentelemetry-semantic-conventions-ai>=0.4.1 (from vllm)\n",
      "  Downloading opentelemetry_semantic_conventions_ai-0.4.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.9.0.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting compressed-tensors==0.9.4 (from vllm)\n",
      "  Downloading vllm-0.9.0.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting compressed-tensors==0.9.4 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading compressed_tensors-0.9.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting vllm\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.9.0-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "  Downloading vllm-0.9.0-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "  Downloading vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
      "Collecting xgrammar==0.1.18 (from vllm)\n",
      "  Downloading vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
      "Collecting xgrammar==0.1.18 (from vllm)\n",
      "  Downloading xgrammar-0.1.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "  Downloading xgrammar-0.1.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting importlib_metadata (from vllm)\n",
      "Collecting importlib_metadata (from vllm)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting compressed-tensors==0.9.3 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting compressed-tensors==0.9.3 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
      "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
      "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.8.5-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
      "  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "  Downloading vllm-0.8.4-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "  Downloading vllm-0.8.3-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "  Downloading vllm-0.8.3-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "Collecting xgrammar==0.1.17 (from vllm)\n",
      "Collecting xgrammar==0.1.17 (from vllm)\n",
      "  Downloading xgrammar-0.1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting gguf==0.10.0 (from vllm)\n",
      "  Downloading xgrammar-0.1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting gguf==0.10.0 (from vllm)\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting compressed-tensors==0.9.2 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting numba==0.61 (from vllm)\n",
      "Collecting compressed-tensors==0.9.2 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting numba==0.61 (from vllm)\n",
      "  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "INFO: pip is still looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "INFO: pip is still looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting xgrammar==0.1.16 (from vllm)\n",
      "  Downloading xgrammar-0.1.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting xgrammar==0.1.16 (from vllm)\n",
      "  Downloading xgrammar-0.1.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting numba==0.60.0 (from vllm)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting vllm\n",
      "Collecting numba==0.60.0 (from vllm)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.8.1-cp38-abi3-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "  Downloading vllm-0.8.1-cp38-abi3-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "  Downloading vllm-0.8.0-cp38-abi3-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "  Downloading vllm-0.8.0-cp38-abi3-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "  Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "  Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xgrammar==0.1.11 (from vllm)\n",
      "Collecting xgrammar==0.1.11 (from vllm)\n",
      "  Downloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting compressed-tensors==0.9.1 (from vllm)\n",
      "  Downloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting compressed-tensors==0.9.1 (from vllm)\n",
      "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting ray==2.40.0 (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting ray==2.40.0 (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /venv/main/lib/python3.10/site-packages (from vllm) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /venv/main/lib/python3.10/site-packages (from vllm) (2.5.1+cu124)\n",
      "Collecting xformers==0.0.28.post3 (from vllm)\n",
      "Collecting xformers==0.0.28.post3 (from vllm)\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm)\n",
      "Collecting astor (from depyf==0.18.0->vllm)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba==0.60.0->vllm)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba==0.60.0->vllm)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: nest_asyncio in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: nest_asyncio in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: referencing in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: referencing in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
      "  Downloading airportsdata-20250706-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
      "  Downloading airportsdata-20250706-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray==2.40.0->ray[adag]==2.40.0->vllm)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray==2.40.0->ray[adag]==2.40.0->vllm)\n",
      "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiosignal in /venv/main/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.4.0)\n",
      "Requirement already satisfied: frozenlist in /venv/main/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.7.0)\n",
      "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: aiosignal in /venv/main/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.4.0)\n",
      "Requirement already satisfied: frozenlist in /venv/main/lib/python3.10/site-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm) (1.7.0)\n",
      "Collecting cupy-cuda12x (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.5.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting cupy-cuda12x (from ray[adag]==2.40.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.5.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting pybind11 (from xgrammar==0.1.11->vllm)\n",
      "  Downloading pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pybind11 (from xgrammar==0.1.11->vllm)\n",
      "  Downloading pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pytest (from xgrammar==0.1.11->vllm)\n",
      "  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pytest (from xgrammar==0.1.11->vllm)\n",
      "  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cli-0.0.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading fastapi_cli-0.0.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting httpx>=0.23.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.23.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jinja2 (from torch<3,>=2.2->bitsandbytes)\n",
      "Collecting jinja2 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.14.8-py3-none-any.whl.metadata (999 bytes)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.14.8-py3-none-any.whl.metadata (999 bytes)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cloud_cli-0.1.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cloud_cli-0.1.4-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rignore-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rignore-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /venv/main/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /venv/main/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /venv/main/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /venv/main/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: decorator in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /venv/main/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: decorator in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /venv/main/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /venv/main/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /venv/main/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /venv/main/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /venv/main/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.26.0)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.52.0->vllm)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.52.0->vllm)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.52.0->vllm)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.52.0->vllm)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless>=4.0.0 (from mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless>=4.0.0 (from mistral_common[opencv]>=1.6.2->vllm)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /venv/main/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /venv/main/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[adag]==2.40.0->vllm)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[adag]==2.40.0->vllm)\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata->vllm)\n",
      "Collecting zipp>=3.20 (from importlib_metadata->vllm)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting iniconfig>=1 (from pytest->xgrammar==0.1.11->vllm)\n",
      "Collecting iniconfig>=1 (from pytest->xgrammar==0.1.11->vllm)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->xgrammar==0.1.11->vllm)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->xgrammar==0.1.11->vllm)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tomli>=1 (from pytest->xgrammar==0.1.11->vllm)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tomli>=1 (from pytest->xgrammar==0.1.11->vllm)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/264.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m264.6/264.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m264.6/264.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/66.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading ray-2.40.0-cp310-cp310-manylinux2014_x86_64.whl (66.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m66.8/66.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m66.8/66.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/16.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "Downloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/18.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading starlette-0.47.1-py3-none-any.whl (72 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading starlette-0.47.1-py3-none-any.whl (72 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastapi_cli-0.0.8-py3-none-any.whl (10 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastapi_cli-0.0.8-py3-none-any.whl (10 kB)\n",
      "Downloading fastapi_cloud_cli-0.1.4-py3-none-any.whl (18 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading fastapi_cloud_cli-0.1.4-py3-none-any.whl (18 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading mistral_common-1.8.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/6.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading mistral_common-1.8.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.96.1-py3-none-any.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.96.1-py3-none-any.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m757.5/757.5 kB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m757.5/757.5 kB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/50.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/6.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading rich_toolkit-0.14.8-py3-none-any.whl (24 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading rich_toolkit-0.14.8-py3-none-any.whl (24 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rignore-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m950.3/950.3 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading rignore-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m950.3/950.3 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/3.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading airportsdata-20250706-py3-none-any.whl (912 kB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/912.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading airportsdata-20250706-py3-none-any.whl (912 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cupy_cuda12x-13.5.1-cp310-cp310-manylinux2014_x86_64.whl (112.4 MB)\n",
      "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/112.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading cupy_cuda12x-13.5.1-cp310-cp310-manylinux2014_x86_64.whl (112.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m112.4/112.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m112.4/112.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
      "Downloading pytest-8.4.1-py3-none-any.whl (365 kB)\n",
      "Downloading pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
      "Downloading pytest-8.4.1-py3-none-any.whl (365 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: sentencepiece, py-cpuinfo, fastrlock, blake3, zipp, websockets, uvloop, tomli, sniffio, shellingham, rignore, python-multipart, python-dotenv, pycountry, pybind11, prometheus_client, pluggy, partial-json-parser, numpy, msgspec, msgpack, mdurl, llvmlite, lark, jiter, jinja2, interegular, iniconfig, httptools, h11, einops, dnspython, distro, diskcache, cloudpickle, astor, airportsdata, uvicorn, tiktoken, pytest, opencv-python-headless, numba, markdown-it-py, importlib_metadata, httpcore, gguf, email-validator, depyf, cupy-cuda12x, anyio, watchfiles, starlette, rich, pydantic-extra-types, lm-format-enforcer, httpx, xformers, typer, rich-toolkit, ray, prometheus-fastapi-instrumentator, outlines_core, openai, fastapi, xgrammar, outlines, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, vllm\n",
      "\u001b[?25lInstalling collected packages: sentencepiece, py-cpuinfo, fastrlock, blake3, zipp, websockets, uvloop, tomli, sniffio, shellingham, rignore, python-multipart, python-dotenv, pycountry, pybind11, prometheus_client, pluggy, partial-json-parser, numpy, msgspec, msgpack, mdurl, llvmlite, lark, jiter, jinja2, interegular, iniconfig, httptools, h11, einops, dnspython, distro, diskcache, cloudpickle, astor, airportsdata, uvicorn, tiktoken, pytest, opencv-python-headless, numba, markdown-it-py, importlib_metadata, httpcore, gguf, email-validator, depyf, cupy-cuda12x, anyio, watchfiles, starlette, rich, pydantic-extra-types, lm-format-enforcer, httpx, xformers, typer, rich-toolkit, ray, prometheus-fastapi-instrumentator, outlines_core, openai, fastapi, xgrammar, outlines, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, vllm\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[90m\u001b[0m \u001b[32m13/71\u001b[0m [pycountry]]\n",
      "\u001b[2K    Found existing installation: numpy 2.1.2\u001b[0m \u001b[32m13/71\u001b[0m [pycountry]\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[0m \u001b[32m13/71\u001b[0m [pycountry]\n",
      "\u001b[2K    Found existing installation: numpy 2.1.2\u001b[0m \u001b[32m13/71\u001b[0m [pycountry]\n",
      "\u001b[2K    Uninstalling numpy-2.1.2:m\u001b[0m \u001b[32m13/71\u001b[0m [pycountry]\n",
      "\u001b[2K    Uninstalling numpy-2.1.2:[0m\u001b[90m\u001b[0m \u001b[32m18/71\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.1.2\u001b[0m \u001b[32m18/71\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.1.2\u001b[0m \u001b[32m18/71\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: jinja2\u001b[0m\u001b[90m\u001b[0m \u001b[32m24/71\u001b[0m [jiter]te]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.4\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.4:m\u001b[90m\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.4\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K  Attempting uninstall: jinja2\u001b[0m\u001b[90m\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.4\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.4:m\u001b[90m\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.4\u001b[0m \u001b[32m24/71\u001b[0m [jiter]\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71/71\u001b[0m [vllm]0m [vllm]0m [compressed-tensors]umentator]\n",
      "\u001b[1A\u001b[2KSuccessfully installed airportsdata-20250706 anyio-4.9.0 astor-0.8.1 blake3-1.0.5 cloudpickle-3.1.1 compressed-tensors-0.9.1 cupy-cuda12x-13.5.1 depyf-0.18.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.7.0 einops-0.8.1 email-validator-2.2.0 fastapi-0.116.1 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.4 fastrlock-0.8.3 gguf-0.10.0 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 importlib_metadata-8.7.0 iniconfig-2.1.0 interegular-0.3.3 jinja2-3.1.6 jiter-0.10.0 lark-1.2.2 llvmlite-0.43.0 lm-format-enforcer-0.10.11 markdown-it-py-3.0.0 mdurl-0.1.2 mistral_common-1.8.1 msgpack-1.1.1 msgspec-0.19.0 numba-0.60.0 numpy-1.26.4 openai-1.96.1 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 pluggy-1.6.0 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.22.1 py-cpuinfo-9.0.0 pybind11-3.0.0 pycountry-24.6.1 pydantic-extra-types-2.10.5 pytest-8.4.1 python-dotenv-1.1.1 python-multipart-0.0.20 ray-2.40.0 rich-14.0.0 rich-toolkit-0.14.8 rignore-0.6.2 sentencepiece-0.2.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.47.1 tiktoken-0.9.0 tomli-2.2.1 typer-0.16.0 uvicorn-0.35.0 uvloop-0.21.0 vllm-0.7.3 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.28.post3 xgrammar-0.1.11 zipp-3.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m71/71\u001b[0m [vllm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed airportsdata-20250706 anyio-4.9.0 astor-0.8.1 blake3-1.0.5 cloudpickle-3.1.1 compressed-tensors-0.9.1 cupy-cuda12x-13.5.1 depyf-0.18.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.7.0 einops-0.8.1 email-validator-2.2.0 fastapi-0.116.1 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.4 fastrlock-0.8.3 gguf-0.10.0 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 importlib_metadata-8.7.0 iniconfig-2.1.0 interegular-0.3.3 jinja2-3.1.6 jiter-0.10.0 lark-1.2.2 llvmlite-0.43.0 lm-format-enforcer-0.10.11 markdown-it-py-3.0.0 mdurl-0.1.2 mistral_common-1.8.1 msgpack-1.1.1 msgspec-0.19.0 numba-0.60.0 numpy-1.26.4 openai-1.96.1 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 pluggy-1.6.0 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.22.1 py-cpuinfo-9.0.0 pybind11-3.0.0 pycountry-24.6.1 pydantic-extra-types-2.10.5 pytest-8.4.1 python-dotenv-1.1.1 python-multipart-0.0.20 ray-2.40.0 rich-14.0.0 rich-toolkit-0.14.8 rignore-0.6.2 sentencepiece-0.2.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.47.1 tiktoken-0.9.0 tomli-2.2.1 typer-0.16.0 uvicorn-0.35.0 uvloop-0.21.0 vllm-0.7.3 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.28.post3 xgrammar-0.1.11 zipp-3.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers trl datasets huggingface_hub bitsandbytes wandb tqdm pillow torchvision peft ipywidgets nbformat vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eigtRq43XTRQ"
   },
   "source": [
    "## Mount Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IHANN2aSilAm"
   },
   "outputs": [],
   "source": [
    "# HF_CACHE = \"/content/drive/MyDrive/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqTcrSFMzrMB",
    "outputId": "3c81b6cc-8ebf-4729-d03a-7ad0838c91db"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive, runtime\n",
    "# import os\n",
    "# drive.mount(\"/content/drive\")\n",
    "\n",
    "# # One shared cache for everything:\n",
    "# HF_CACHE = \"/content/drive/MyDrive/hf_cache\"\n",
    "# !mkdir -p \"$HF_CACHE\"\n",
    "\n",
    "# os.environ[\"HF_HOME\"] = HF_CACHE           # generic root\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = HF_CACHE\n",
    "# os.environ[\"HF_DATASETS_CACHE\"] = HF_CACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rR7z4T_XPKT"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEBdNJX6Mv2M",
    "outputId": "86e10b33-36b0-4ebd-efb7-2f5100651f07"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import contextlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import log_softmax, softplus\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    LlavaNextForConditionalGeneration,\n",
    "    LlavaNextProcessor,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eay3pB2CVv9m"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w7jOqSV3VzUt"
   },
   "outputs": [],
   "source": [
    "MODEL_ID          = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "DATASET_NAME      = \"openbmb/RLAIF-V-Dataset\"\n",
    "WANDB_PROJECT     = \"llava-qlora-orpo\"\n",
    "OUTPUT_DIR        = \"../logs/\"\n",
    "\n",
    "!mkdir -p \"$OUTPUT_DIR\"\n",
    "# USE_QLORA         = False \n",
    "# QLORA had a lot of issues with the Mistral model\n",
    "# SO I dropped it for now\n",
    "\n",
    "TRAIN_BATCH_SIZE  = 1 \n",
    "VAL_BATCH_SIZE    = 6\n",
    "TEST_BATCH_SIZE   = 6\n",
    "GRAD_ACC_STEPS    = 4          # effective batch = TRAIN_BATCH_SIZE  GRAD_ACC_STEPS\n",
    "EPOCHS            = 1\n",
    "LEARNING_RATE     = 2e-4\n",
    "WARMUP_RATIO      = 0.03\n",
    "\n",
    "VAL_RATIO         = 0.05      \n",
    "TEST_RATIO        = 0.20  \n",
    "\n",
    "LORA_R            = 8  \n",
    "LORA_ALPHA        = 16 \n",
    "\n",
    "LORA_DROPOUT      = 0.05\n",
    "ORPO_LAMBDA       = 5\n",
    "\n",
    "LOG_EVERY_STEPS   = 4\n",
    "VAL_EVERY_STEPS   = 200\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "# Maximum number of tokens for the answer\n",
    "MAX_ANSWER_TOKENS = 128 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w1a392FM07E"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0bc34b4a59744eb0b83001fe470a6efb",
      "a5e68b2c41654c0a88f0a33d25c566ca",
      "4eb4ff04a9154017819a2d8d91aa7594",
      "db1e32da1e3c41d08001ee2f84fbdd20",
      "b357a26e2974408f95ceff070ecdbbcb",
      "fdffe38e72e14589b8e02c05a0f7d460",
      "60dfd26adca048c6927cb1c317701ae9",
      "15c8ea12e1214f9e91e4cefa9f779f39",
      "632c2b5a95e744be9671406be88e68ae",
      "8b3166a5cd4d493298f52075284f2354",
      "88ab1a9621b844f692943960d7fb1077"
     ]
    },
    "id": "NMzHaojPxewv",
    "outputId": "b6ef595e-9e61-44df-bb8f-0addffed4553"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736d6b46ef464ec2a75619cdf361054c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(MODEL_ID, use_fast=True)\n",
    "TOKENIZER = processor.tokenizer\n",
    "EOS_ID = TOKENIZER.eos_token_id\n",
    "\n",
    "base_model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# if USE_QLORA:\n",
    "#     # 4bit base + gradientckpt\n",
    "#     bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#     )\n",
    "\n",
    "#     base_model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "#         MODEL_ID,\n",
    "#         quantization_config=bnb_config,\n",
    "#         torch_dtype=torch.float16,\n",
    "#         low_cpu_mem_usage=True,\n",
    "#         device_map=\"auto\",\n",
    "#     )\n",
    "\n",
    "#     base_model = prepare_model_for_kbit_training(\n",
    "#         base_model, use_gradient_checkpointing=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u6cqLn7WsDu",
    "outputId": "215a9344-6ead-4c4b-9f21-155cce322fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 22,151,168 || all params: 7,588,898,816 || trainable%: 0.2919\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Owbs85F6M87e"
   },
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfaV050EJPIa"
   },
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def temporary_padding_side(tokenizer, side):\n",
    "    \"\"\"Temporarily change padding side (left/right) inside a `with` block.\"\"\"\n",
    "    original = tokenizer.padding_side\n",
    "    tokenizer.padding_side = side\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        tokenizer.padding_side = original\n",
    "\n",
    "\n",
    "def build_prompt_inputs(images, questions):\n",
    "    \"\"\"Tokenise the (question + image placeholder) prompt with leftpadding.\"\"\"\n",
    "    conversations = [\n",
    "        [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": q}, {\"type\": \"image\"}]}]\n",
    "        for q in questions\n",
    "    ]\n",
    "    prompts = [processor.apply_chat_template(c, add_generation_prompt=True) for c in conversations]\n",
    "    encoded = processor(images=images, text=prompts, padding=True, return_tensors=\"pt\")\n",
    "    return {k: v.to(DEVICE) for k, v in encoded.items()}\n",
    "\n",
    "\n",
    "def tokenize_answers(texts, max_length):\n",
    "    \"\"\"Rightpad assistant answers and append EOS.\"\"\"\n",
    "\n",
    "    # Reason for the right pad tokenization -\n",
    "    # later I will concatenate prompt tokens and potential answer tokens,\n",
    "    # to get logits in one go, without writing a loop.\n",
    "    # Having pad tokens in the middle seems very confusing\n",
    "    # and can be misleading and couse errors in the future.\n",
    "\n",
    "    with temporary_padding_side(TOKENIZER, \"right\"):\n",
    "        encoded = TOKENIZER(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    ids, mask = encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "    eos_column = torch.full((ids.size(0), 1), EOS_ID, dtype=ids.dtype)\n",
    "    ids = torch.cat([ids, eos_column], dim=1)\n",
    "    mask = torch.cat([mask, torch.ones_like(eos_column)], dim=1)\n",
    "\n",
    "    if max_length is not None:\n",
    "        # Trim if longer than max_length\n",
    "        ids = ids[:, :max_length]\n",
    "        mask = mask[:, :max_length]\n",
    "\n",
    "    return ids.to(DEVICE), mask.to(DEVICE)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[\"image\"] for item in batch]\n",
    "    questions = [item[\"question\"] for item in batch]\n",
    "    chosen_texts = [item[\"chosen\"] for item in batch]\n",
    "    rejected_texts = [item[\"rejected\"] for item in batch]\n",
    "\n",
    "    prompt_inputs = build_prompt_inputs(images, questions)\n",
    "    chosen_ids, chosen_mask = tokenize_answers(chosen_texts, max_length=MAX_ANSWER_TOKENS)\n",
    "    rejected_ids, rejected_mask = tokenize_answers(rejected_texts, max_length=MAX_ANSWER_TOKENS)\n",
    "\n",
    "    return prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e-Ex_V7WaTKp"
   },
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(DATASET_NAME, split=\"train[:5%]\")\n",
    "first_split = raw_dataset.train_test_split(test_size=VAL_RATIO + TEST_RATIO, seed=42)\n",
    "train_dataset = first_split[\"train\"]\n",
    "val_test_dataset = first_split[\"test\"]\n",
    "val_fraction_of_tmp = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "second_split = val_test_dataset.train_test_split(test_size=1 - val_fraction_of_tmp, seed=42)\n",
    "val_dataset = second_split[\"train\"]\n",
    "test_dataset = second_split[\"test\"]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s-hUm50NN5B"
   },
   "source": [
    "# Get logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_cache(prompt_inputs):\n",
    "    \"\"\"Get the last logits and past key values for the prompt inputs.\"\"\"\n",
    "    \n",
    "    training  = model.training\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(**prompt_inputs, return_dict=True)\n",
    "\n",
    "    if training:\n",
    "        model.train()\n",
    "\n",
    "    return out.logits[:, -1:, :], out.past_key_values\n",
    "\n",
    "def answer_logits(prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask):\n",
    "    \"\"\"Get logits for the chosen and rejected answers, aligned with the prompt inputs.\"\"\"\n",
    "\n",
    "    last_logits, prompt_kv = get_prompt_cache(prompt_inputs)\n",
    "\n",
    "    # raw logits when we feed the full answers\n",
    "    raw_chosen = model(\n",
    "        input_ids=chosen_ids,\n",
    "        attention_mask=chosen_mask,\n",
    "        past_key_values=prompt_kv\n",
    "    ).logits          # (B,N,V)\n",
    "\n",
    "    raw_rejected = model(\n",
    "        input_ids=rejected_ids,\n",
    "        attention_mask=rejected_mask,\n",
    "        past_key_values=prompt_kv\n",
    "    ).logits          # (B,N,V)\n",
    "\n",
    "    # align: prepend last_prompt_logits and drop the last timestep\n",
    "    chosen_logits = torch.cat([last_logits, raw_chosen[:, :-1, :]],  dim=1)\n",
    "    rejected_logits = torch.cat([last_logits, raw_rejected[:, :-1, :]], dim=1)\n",
    "\n",
    "    return chosen_logits, rejected_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_logp(logits, ids):\n",
    "    \"\"\"Get log probabilities for the given token IDs from the logits.\"\"\"\n",
    "    logp = log_softmax(logits, dim=-1)\n",
    "    return logp.gather(2, ids.unsqueeze(-1)).squeeze(-1)    # (B,N)\n",
    "\n",
    "def log_prob(logs, mask):\n",
    "    \"\"\"Get the average log probability for the given logs and mask.\"\"\"\n",
    "    return (logs * mask).sum(dim=-1) / mask.sum(dim=-1)\n",
    "\n",
    "def log_odds(log_prob):\n",
    "    \"\"\"Convert log probability to log odds.\"\"\"\n",
    "    return log_prob - torch.log1p(-torch.exp(log_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_orpo(chosen_logits, rejected_logits, chosen_ids, rejected_ids, chosen_mask, rejected_mask, lam):\n",
    "    \"\"\"Calculate the ORPO loss for the chosen and rejected logits.\"\"\"\n",
    "    chosen_logits = token_logp(chosen_logits, chosen_ids)   # (B,N)\n",
    "    rejected_logits = token_logp(rejected_logits, rejected_ids)  # (B,N)\n",
    "\n",
    "    chosen_logp = log_prob(chosen_logits, chosen_mask)  # (B,)\n",
    "    rejected_logp = log_prob(rejected_logits, rejected_mask)  # (B,)\n",
    "    \n",
    "    log_odds_chosen = log_odds(chosen_logp)  # (B,)\n",
    "    log_odds_rejected = log_odds(rejected_logp)  # (B,)\n",
    "\n",
    "    L_sft = -chosen_logp.mean()  # supervised fine-tuning loss\n",
    "    L_or = -torch.log(\n",
    "        torch.sigmoid(log_odds_chosen - log_odds_rejected)\n",
    "    ).mean()\n",
    "\n",
    "\n",
    "    return L_sft + lam * L_or, L_sft, L_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9729758f4b9c4410b8bc95e62cad67cf",
      "67f99b3f4e8e4757ad38c91d52e1611d",
      "053400e801a4462795fa9e419ac5cb6e",
      "4524c55cb0434ff4b57fa375b4714221",
      "15d0bfbe6dca4ab7b4f9232fca710300",
      "bd86c15f1efc4c4c8f3572db97272742",
      "fa2f5d1ddd174838a8816ba1d0643fa4",
      "9f07b87485f341879da1bbded82ca170",
      "45d21ebd5c6246b6ae556416b0f265f4",
      "7545b54978394866b1857651c60a697c",
      "b14c52d996af42318011f89b94a4770e"
     ]
    },
    "id": "9SYjobt5a6J9",
    "outputId": "dbceb45d-bbdf-4848-81c0-fb9abf2e4cb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrach0v\u001b[0m (\u001b[33mcowboy_bebop\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/ORPO_LLaVA/code/wandb/run-20250716_134246-5bg71lmn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/5bg71lmn' target=\"_blank\">dazzling-elevator-27</a></strong> to <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/5bg71lmn' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/5bg71lmn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da25affa706466d88c922b70c4b4b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/3117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b6d7f5e3324f76ac0d601f0f1f70f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 10.5060 at step 200  adapters saved to ../logs//step_200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92ca7d6d30e4fbdbb037c4568360840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676cf147a651423a81abd9b14e9af8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 10.3085 at step 600  adapters saved to ../logs//step_600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc90492ed7044adb5fc34e6526246cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735102bfdbd04dde8e1ef9b739d136e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 10.0305 at step 1000  adapters saved to ../logs//step_1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e3e23aa4eb4f6ca9312643f41c08bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ea7e4c156341968702f0621cf2c13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.9580 at step 1400  adapters saved to ../logs//step_1400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba25a2ab65c40719d9007c3d8623019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.8866 at step 1600  adapters saved to ../logs//step_1600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc831c2659bb4b819495b2bc5eba3906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.8009 at step 1800  adapters saved to ../logs//step_1800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bf2624536248dcb4f13eff41e23f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.7561 at step 2000  adapters saved to ../logs//step_2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec06bf143eb46e09d70d586c57bb270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.7541 at step 2200  adapters saved to ../logs//step_2200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007849f6aeab42ebab52460bc56505f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158430c562284114a14916c6d8fe482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best val_loss 9.6849 at step 2600  adapters saved to ../logs//step_2600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba7402eed9f4cc9a0cac305d1e716f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e0fc0581ad4db98940c1d6fef282ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a89c0ddbd24fc1bb6288414c9b7615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.95), weight_decay=0.0)\n",
    "steps_per_epoch = len(train_loader) // GRAD_ACC_STEPS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    int(steps_per_epoch * EPOCHS * WARMUP_RATIO),\n",
    "    steps_per_epoch * EPOCHS,\n",
    ")\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT, config={k: v for k, v in globals().items() if k.isupper()})\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=LOG_EVERY_STEPS)\n",
    "\n",
    "best_val = float(\"inf\")   # lower is better for ORPO\n",
    "best_step = -1\n",
    "\n",
    "\n",
    "model.train()\n",
    "acc_steps = 0\n",
    "running_loss = 0.0  # To accumulate loss for average\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for global_step, batch in tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask)\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, \n",
    "            rejected_logits, \n",
    "            chosen_ids, \n",
    "            rejected_ids, \n",
    "            chosen_mask, \n",
    "            rejected_mask, \n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "        \n",
    "        loss = loss_orpo_val / GRAD_ACC_STEPS \n",
    "        loss.backward()\n",
    "\n",
    "        acc_steps += 1\n",
    "        running_loss += loss.item() * GRAD_ACC_STEPS # Accumulate original loss before division\n",
    "        \n",
    "        if acc_steps == GRAD_ACC_STEPS:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad() \n",
    "            acc_steps = 0\n",
    "            \n",
    "\n",
    "        if global_step % LOG_EVERY_STEPS == 0:\n",
    "            avg_loss = running_loss / LOG_EVERY_STEPS\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train/orpo_loss\": avg_loss,\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"train/loss_orpo\": loss_orpo_val.item(),\n",
    "                    \"train/loss_sft\": loss_sft_val.item(),\n",
    "                    \"train/loss_or\": loss_or_val.item(),\n",
    "                },\n",
    "                step=global_step\n",
    "            )\n",
    "            running_loss = 0.0 # Reset running loss\n",
    "\n",
    "\n",
    "        if global_step % VAL_EVERY_STEPS == 0 or global_step == len(train_loader) - 1:\n",
    "            model.eval()\n",
    "            val_orpo_list, val_sft_list, val_or_list = [], [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                    prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "                    # single prompt pass, same as training\n",
    "                    chosen_logits, rejected_logits = answer_logits(\n",
    "                        prompt_inputs,\n",
    "                        chosen_ids,   chosen_mask,\n",
    "                        rejected_ids, rejected_mask\n",
    "                    )\n",
    "\n",
    "                    loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "                        chosen_logits, rejected_logits,\n",
    "                        chosen_ids, rejected_ids,\n",
    "                        chosen_mask, rejected_mask,\n",
    "                        ORPO_LAMBDA\n",
    "                    )\n",
    "\n",
    "                    val_orpo_list.append(loss_orpo_val.item())\n",
    "                    val_sft_list.append(loss_sft_val.item())\n",
    "                    val_or_list.append(loss_or_val.item())\n",
    "\n",
    "            mean_val_orpo = sum(val_orpo_list) / len(val_orpo_list)\n",
    "\n",
    "            # checkpoint if best\n",
    "            if mean_val_orpo < best_val:\n",
    "                best_val = mean_val_orpo\n",
    "                best_step = global_step\n",
    "                ckpt_dir = f\"{OUTPUT_DIR}/step_{best_step}\"\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "                model.save_pretrained(ckpt_dir)\n",
    "                wandb.run.summary.update({\n",
    "                    \"best_val_loss\": best_val,\n",
    "                    \"best_step\": best_step\n",
    "                })\n",
    "                print(f\" New best val_loss {best_val:.4f} at step {best_step}  adapters saved to {ckpt_dir}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"val/orpo_loss\": mean_val_orpo,\n",
    "                \"val/loss_sft\":  sum(val_sft_list) / len(val_sft_list),\n",
    "                \"val/loss_or\":   sum(val_or_list)  / len(val_or_list),\n",
    "            }, step=global_step)\n",
    "\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = f\"{OUTPUT_DIR}/last\"\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "model.save_pretrained(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LfNREqx9s_IH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from step 2600: ../logs//step_2600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61a7ea8a8034e948a4d9eb28d83f613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "ORPO Loss: 10.1229\n",
      "SFT Loss: 7.0619\n",
      "OR Loss: 0.6122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td></td></tr><tr><td>test/loss_or</td><td></td></tr><tr><td>test/loss_sft</td><td></td></tr><tr><td>test/orpo_loss</td><td></td></tr><tr><td>train/loss_or</td><td></td></tr><tr><td>train/loss_orpo</td><td></td></tr><tr><td>train/loss_sft</td><td></td></tr><tr><td>train/orpo_loss</td><td></td></tr><tr><td>val/loss_or</td><td></td></tr><tr><td>val/loss_sft</td><td></td></tr><tr><td>val/orpo_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_step</td><td>2600</td></tr><tr><td>best_val_loss</td><td>9.68493</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>test/loss_or</td><td>0.61222</td></tr><tr><td>test/loss_sft</td><td>7.06194</td></tr><tr><td>test/orpo_loss</td><td>10.12295</td></tr><tr><td>train/loss_or</td><td>0.19214</td></tr><tr><td>train/loss_orpo</td><td>4.65625</td></tr><tr><td>train/loss_sft</td><td>3.69727</td></tr><tr><td>train/orpo_loss</td><td>4.33838</td></tr><tr><td>val/loss_or</td><td>0.58039</td></tr><tr><td>val/loss_sft</td><td>6.80737</td></tr><tr><td>val/orpo_loss</td><td>9.70915</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-elevator-27</strong> at: <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/5bg71lmn' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/5bg71lmn</a><br> View project at: <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250716_134246-5bg71lmn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "if best_step != -1:\n",
    "    best_ckpt_dir = f\"{OUTPUT_DIR}/step_{best_step}\"\n",
    "    print(f\"Loading best model from step {best_step}: {best_ckpt_dir}\")\n",
    "    model.load_adapter(best_ckpt_dir, adapter_name=\"best\")\n",
    "    model.set_adapter(\"best\")\n",
    "else:\n",
    "    print(\"No best model found, using current model state\")\n",
    "\n",
    "model.eval()\n",
    "test_orpo_list, test_sft_list, test_or_list = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(\n",
    "            prompt_inputs,\n",
    "            chosen_ids, chosen_mask,\n",
    "            rejected_ids, rejected_mask\n",
    "        )\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, rejected_logits,\n",
    "            chosen_ids, rejected_ids,\n",
    "            chosen_mask, rejected_mask,\n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "\n",
    "        test_orpo_list.append(loss_orpo_val.item())\n",
    "        test_sft_list.append(loss_sft_val.item())\n",
    "        test_or_list.append(loss_or_val.item())\n",
    "\n",
    "mean_test_orpo = sum(test_orpo_list) / len(test_orpo_list)\n",
    "mean_test_sft = sum(test_sft_list) / len(test_sft_list)\n",
    "mean_test_or = sum(test_or_list) / len(test_or_list)\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"ORPO Loss: {mean_test_orpo:.4f}\")\n",
    "print(f\"SFT Loss: {mean_test_sft:.4f}\")\n",
    "print(f\"OR Loss: {mean_test_or:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test/orpo_loss\": mean_test_orpo,\n",
    "    \"test/loss_sft\": mean_test_sft,\n",
    "    \"test/loss_or\": mean_test_or,\n",
    "})\n",
    "\n",
    "#  save adapters & finish \n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD2hTAP7NllA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a052f1e4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMh8o9CVaj9ICPJkX1C/lN8",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "053400e801a4462795fa9e419ac5cb6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f07b87485f341879da1bbded82ca170",
      "max": 7482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45d21ebd5c6246b6ae556416b0f265f4",
      "value": 0
     }
    },
    "0bc34b4a59744eb0b83001fe470a6efb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5e68b2c41654c0a88f0a33d25c566ca",
       "IPY_MODEL_4eb4ff04a9154017819a2d8d91aa7594",
       "IPY_MODEL_db1e32da1e3c41d08001ee2f84fbdd20"
      ],
      "layout": "IPY_MODEL_b357a26e2974408f95ceff070ecdbbcb"
     }
    },
    "15c8ea12e1214f9e91e4cefa9f779f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15d0bfbe6dca4ab7b4f9232fca710300": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4524c55cb0434ff4b57fa375b4714221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7545b54978394866b1857651c60a697c",
      "placeholder": "",
      "style": "IPY_MODEL_b14c52d996af42318011f89b94a4770e",
      "value": "0/7482[00:00&lt;?,?it/s]"
     }
    },
    "45d21ebd5c6246b6ae556416b0f265f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4eb4ff04a9154017819a2d8d91aa7594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15c8ea12e1214f9e91e4cefa9f779f39",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_632c2b5a95e744be9671406be88e68ae",
      "value": 4
     }
    },
    "60dfd26adca048c6927cb1c317701ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "632c2b5a95e744be9671406be88e68ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67f99b3f4e8e4757ad38c91d52e1611d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd86c15f1efc4c4c8f3572db97272742",
      "placeholder": "",
      "style": "IPY_MODEL_fa2f5d1ddd174838a8816ba1d0643fa4",
      "value": "Epoch1/1:0%"
     }
    },
    "7545b54978394866b1857651c60a697c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ab1a9621b844f692943960d7fb1077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3166a5cd4d493298f52075284f2354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9729758f4b9c4410b8bc95e62cad67cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f99b3f4e8e4757ad38c91d52e1611d",
       "IPY_MODEL_053400e801a4462795fa9e419ac5cb6e",
       "IPY_MODEL_4524c55cb0434ff4b57fa375b4714221"
      ],
      "layout": "IPY_MODEL_15d0bfbe6dca4ab7b4f9232fca710300"
     }
    },
    "9f07b87485f341879da1bbded82ca170": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5e68b2c41654c0a88f0a33d25c566ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdffe38e72e14589b8e02c05a0f7d460",
      "placeholder": "",
      "style": "IPY_MODEL_60dfd26adca048c6927cb1c317701ae9",
      "value": "Loadingcheckpointshards:100%"
     }
    },
    "b14c52d996af42318011f89b94a4770e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b357a26e2974408f95ceff070ecdbbcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd86c15f1efc4c4c8f3572db97272742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1e32da1e3c41d08001ee2f84fbdd20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b3166a5cd4d493298f52075284f2354",
      "placeholder": "",
      "style": "IPY_MODEL_88ab1a9621b844f692943960d7fb1077",
      "value": "4/4[05:41&lt;00:00,70.87s/it]"
     }
    },
    "fa2f5d1ddd174838a8816ba1d0643fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdffe38e72e14589b8e02c05a0f7d460": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
