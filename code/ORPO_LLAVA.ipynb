{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rR7z4T_XPKT"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEBdNJX6Mv2M",
    "outputId": "86e10b33-36b0-4ebd-efb7-2f5100651f07"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    LlavaNextForConditionalGeneration,\n",
    "    LlavaNextProcessor,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eay3pB2CVv9m"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w7jOqSV3VzUt"
   },
   "outputs": [],
   "source": [
    "from config import (\n",
    "    MODEL_ID,\n",
    "    DATASET_NAME,\n",
    "    WANDB_PROJECT,\n",
    "    OUTPUT_DIR,\n",
    "    # USE_QLORA,\n",
    "    TRAIN_BATCH_SIZE,\n",
    "    VAL_BATCH_SIZE,\n",
    "    TEST_BATCH_SIZE,\n",
    "    GRAD_ACC_STEPS,\n",
    "    EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    WARMUP_RATIO,\n",
    "    VAL_RATIO,\n",
    "    TEST_RATIO,\n",
    "    LORA_R,\n",
    "    LORA_ALPHA,\n",
    "    LORA_DROPOUT,\n",
    "    ORPO_LAMBDA,\n",
    "    LOG_EVERY_STEPS,\n",
    "    VAL_EVERY_STEPS,\n",
    "    DEVICE,\n",
    "    MAX_ANSWER_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7w1a392FM07E"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0bc34b4a59744eb0b83001fe470a6efb",
      "a5e68b2c41654c0a88f0a33d25c566ca",
      "4eb4ff04a9154017819a2d8d91aa7594",
      "db1e32da1e3c41d08001ee2f84fbdd20",
      "b357a26e2974408f95ceff070ecdbbcb",
      "fdffe38e72e14589b8e02c05a0f7d460",
      "60dfd26adca048c6927cb1c317701ae9",
      "15c8ea12e1214f9e91e4cefa9f779f39",
      "632c2b5a95e744be9671406be88e68ae",
      "8b3166a5cd4d493298f52075284f2354",
      "88ab1a9621b844f692943960d7fb1077"
     ]
    },
    "id": "NMzHaojPxewv",
    "outputId": "b6ef595e-9e61-44df-bb8f-0addffed4553"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e3357e06a4908a63adbdd56f71c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(MODEL_ID, use_fast=True)\n",
    "TOKENIZER = processor.tokenizer\n",
    "EOS_ID = TOKENIZER.eos_token_id\n",
    "\n",
    "base_model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# if USE_QLORA:\n",
    "#     # 4‑bit base + gradient‑ckpt\n",
    "#     bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#     )\n",
    "\n",
    "#     base_model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "#         MODEL_ID,\n",
    "#         quantization_config=bnb_config,\n",
    "#         torch_dtype=torch.float16,\n",
    "#         low_cpu_mem_usage=True,\n",
    "#         device_map=\"auto\",\n",
    "#     )\n",
    "\n",
    "#     base_model = prepare_model_for_kbit_training(\n",
    "#         base_model, use_gradient_checkpointing=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u6cqLn7WsDu",
    "outputId": "215a9344-6ead-4c4b-9f21-155cce322fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 22,151,168 || all params: 7,588,898,816 || trainable%: 0.2919\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Owbs85F6M87e"
   },
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BfaV050EJPIa"
   },
   "outputs": [],
   "source": [
    "from dataloader_helper import collate_fn\n",
    "from functools import partial\n",
    "\n",
    "collate_fn = partial(\n",
    "    collate_fn,\n",
    "    processor=processor,\n",
    "    DEVICE=DEVICE,\n",
    "    MAX_ANSWER_TOKENS=MAX_ANSWER_TOKENS,\n",
    "    TOKENIZER=TOKENIZER,\n",
    "    EOS_ID=EOS_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e-Ex_V7WaTKp"
   },
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(DATASET_NAME, split=\"train[:5%]\")\n",
    "first_split = raw_dataset.train_test_split(test_size=VAL_RATIO + TEST_RATIO, seed=42)\n",
    "train_dataset = first_split[\"train\"]\n",
    "val_test_dataset = first_split[\"test\"]\n",
    "val_fraction_of_tmp = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "second_split = val_test_dataset.train_test_split(test_size=1 - val_fraction_of_tmp, seed=42)\n",
    "val_dataset = second_split[\"train\"]\n",
    "test_dataset = second_split[\"test\"]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e546199e98f4a319846a58bcaad9192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/3117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248731c8186049e4bf2b29d7fdebc066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd1e03771fb4eadb83d3b7efddcebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to ../logs/\n",
      "Train dataset: 3117 samples\n",
      "Validation dataset: 208 samples\n",
      "Test dataset: 832 samples\n"
     ]
    }
   ],
   "source": [
    "# Save train_dataset, val_dataset and test_dataset to OUTPUT_DIR\n",
    "train_dataset.save_to_disk(f\"{OUTPUT_DIR}/train_dataset\")\n",
    "val_dataset.save_to_disk(f\"{OUTPUT_DIR}/val_dataset\")\n",
    "test_dataset.save_to_disk(f\"{OUTPUT_DIR}/test_dataset\")\n",
    "\n",
    "print(f\"Datasets saved to {OUTPUT_DIR}\")\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Validation dataset: {len(val_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s-hUm50NN5B"
   },
   "source": [
    "# Get logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orpo_helper import answer_logits, loss_orpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9729758f4b9c4410b8bc95e62cad67cf",
      "67f99b3f4e8e4757ad38c91d52e1611d",
      "053400e801a4462795fa9e419ac5cb6e",
      "4524c55cb0434ff4b57fa375b4714221",
      "15d0bfbe6dca4ab7b4f9232fca710300",
      "bd86c15f1efc4c4c8f3572db97272742",
      "fa2f5d1ddd174838a8816ba1d0643fa4",
      "9f07b87485f341879da1bbded82ca170",
      "45d21ebd5c6246b6ae556416b0f265f4",
      "7545b54978394866b1857651c60a697c",
      "b14c52d996af42318011f89b94a4770e"
     ]
    },
    "id": "9SYjobt5a6J9",
    "outputId": "dbceb45d-bbdf-4848-81c0-fb9abf2e4cb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrach0v\u001b[0m (\u001b[33mcowboy_bebop\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/ORPO_LLaVA/code/wandb/run-20250716_164448-zdwscdki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/zdwscdki' target=\"_blank\">different-cosmos-30</a></strong> to <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/zdwscdki' target=\"_blank\">https://wandb.ai/cowboy_bebop/llava-qlora-orpo/runs/zdwscdki</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0466ba6549544262842d6e7d9bb6a97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/3117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab6d75929884af5bb156b5140723dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ New best val_loss 13.6699 at step 200 — adapters saved to ../logs//step_200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9c8cd0aede43c5a539edb5f1b38020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ New best val_loss 13.6022 at step 400 — adapters saved to ../logs//step_400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06c49e4f4c34015943cef7c115c03d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6068f6749fd441fbbda6d39b30b0965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521db253ca534f64bdc8112e5510b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b2316d707e4b77a4b03be8989a1aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3b29bb3d4c4cf7af46d87f5e61b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ New best val_loss 13.2326 at step 1400 — adapters saved to ../logs//step_1400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad69e4460aa4551900d12b43fe7f26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b6c44a054148e5b739a1c2d1fe1c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50882dd9523a47c9bfb58a2f666aabb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07e93f027554069928b64831519bbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bd7d936c0a4457bd5e51e867263112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bff0ba1cfd4573b413cf1f293bfd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004dc667d630425eb9acb1ed9eba0c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3ad65b036b428bb66b969b502bcc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e932ae712d044615b98dc0e0944bd543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.95), weight_decay=0.0)\n",
    "steps_per_epoch = len(train_loader) // GRAD_ACC_STEPS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    int(steps_per_epoch * EPOCHS * WARMUP_RATIO),\n",
    "    steps_per_epoch * EPOCHS,\n",
    ")\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT, config={k: v for k, v in globals().items() if k.isupper()})\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=LOG_EVERY_STEPS)\n",
    "\n",
    "best_val = float(\"inf\")   # lower is better for ORPO\n",
    "best_step = -1\n",
    "\n",
    "\n",
    "model.train()\n",
    "acc_steps = 0\n",
    "running_loss = 0.0  # To accumulate loss for average\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for global_step, batch in tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(model, prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask)\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, \n",
    "            rejected_logits, \n",
    "            chosen_ids, \n",
    "            rejected_ids, \n",
    "            chosen_mask, \n",
    "            rejected_mask, \n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "        \n",
    "        loss = loss_orpo_val / GRAD_ACC_STEPS \n",
    "        loss.backward()\n",
    "\n",
    "        acc_steps += 1\n",
    "        running_loss += loss.item() * GRAD_ACC_STEPS # Accumulate original loss before division\n",
    "        \n",
    "        if acc_steps == GRAD_ACC_STEPS:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad() \n",
    "            acc_steps = 0\n",
    "            \n",
    "\n",
    "        if global_step % LOG_EVERY_STEPS == 0:\n",
    "            avg_loss = running_loss / LOG_EVERY_STEPS\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"train/orpo_loss\": avg_loss,\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"train/loss_orpo\": loss_orpo_val.item(),\n",
    "                    \"train/loss_sft\": loss_sft_val.item(),\n",
    "                    \"train/loss_or\": loss_or_val.item(),\n",
    "                },\n",
    "                step=global_step\n",
    "            )\n",
    "            running_loss = 0.0 # Reset running loss\n",
    "\n",
    "\n",
    "        if global_step % VAL_EVERY_STEPS == 0 or global_step == len(train_loader) - 1:\n",
    "            model.eval()\n",
    "            val_orpo_list, val_sft_list, val_or_list = [], [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                    prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "                    # single prompt pass, same as training\n",
    "                    chosen_logits, rejected_logits = answer_logits(\n",
    "                        model,\n",
    "                        prompt_inputs,\n",
    "                        chosen_ids,   chosen_mask,\n",
    "                        rejected_ids, rejected_mask\n",
    "                    )\n",
    "\n",
    "                    loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "                        chosen_logits, rejected_logits,\n",
    "                        chosen_ids, rejected_ids,\n",
    "                        chosen_mask, rejected_mask,\n",
    "                        ORPO_LAMBDA\n",
    "                    )\n",
    "\n",
    "                    val_orpo_list.append(loss_orpo_val.item())\n",
    "                    val_sft_list.append(loss_sft_val.item())\n",
    "                    val_or_list.append(loss_or_val.item())\n",
    "\n",
    "            mean_val_orpo = sum(val_orpo_list) / len(val_orpo_list)\n",
    "\n",
    "            # checkpoint if best\n",
    "            if mean_val_orpo < best_val:\n",
    "                best_val = mean_val_orpo\n",
    "                best_step = global_step\n",
    "                ckpt_dir = f\"{OUTPUT_DIR}/step_{wandb.run.name}_{best_step}\"\n",
    "                os.makedirs(ckpt_dir, exist_ok=True)\n",
    "                model.save_pretrained(ckpt_dir)\n",
    "                wandb.run.summary.update({\n",
    "                    \"best_val_loss\": best_val,\n",
    "                    \"best_step\": best_step\n",
    "                })\n",
    "                print(f\"★ New best val_loss {best_val:.4f} at step {best_step} — adapters saved to {ckpt_dir}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"val/orpo_loss\": mean_val_orpo,\n",
    "                \"val/loss_sft\":  sum(val_sft_list) / len(val_sft_list),\n",
    "                \"val/loss_or\":   sum(val_or_list)  / len(val_or_list),\n",
    "            }, step=global_step)\n",
    "\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = f\"{OUTPUT_DIR}/last\"\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "model.save_pretrained(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfNREqx9s_IH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from step 1400: ../logs//step_1400\n",
      "Testing with adapter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab1580bc851438884919f49830c3259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing with adapter:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results (with adapter):\n",
      "ORPO Loss: 13.5965\n",
      "SFT Loss: 7.4400\n",
      "OR Loss: 0.6156\n",
      "\n",
      "Testing without adapter (base model)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No adapter loaded. Please load an adapter first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Test without adapter (base model)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting without adapter (base model)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_adapters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m base_test_orpo_list, base_test_sft_list, base_test_or_list \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/integrations/peft.py:406\u001b[0m, in \u001b[0;36mPeftAdapterMixin.disable_adapters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m check_peft_version(min_version\u001b[38;5;241m=\u001b[39mMIN_PEFT_VERSION)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adapter loaded. Please load an adapter first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTunerLayer\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModulesToSaveWrapper\n",
      "\u001b[0;31mValueError\u001b[0m: No adapter loaded. Please load an adapter first."
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "if best_step != -1:\n",
    "    best_ckpt_dir = f\"{OUTPUT_DIR}/step_{best_step}\"\n",
    "    print(f\"Loading best model from step {best_step}: {best_ckpt_dir}\")\n",
    "    model.load_adapter(best_ckpt_dir, adapter_name=\"best\")\n",
    "    model.set_adapter(\"best\")\n",
    "else:\n",
    "    print(\"No best model found, using current model state\")\n",
    "\n",
    "# Test with adapter\n",
    "print(\"Testing with adapter...\")\n",
    "model.eval()\n",
    "test_orpo_list, test_sft_list, test_or_list = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing with adapter\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(\n",
    "            model, prompt_inputs,\n",
    "            chosen_ids, chosen_mask,\n",
    "            rejected_ids, rejected_mask\n",
    "        )\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, rejected_logits,\n",
    "            chosen_ids, rejected_ids,\n",
    "            chosen_mask, rejected_mask,\n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "\n",
    "        test_orpo_list.append(loss_orpo_val.item())\n",
    "        test_sft_list.append(loss_sft_val.item())\n",
    "        test_or_list.append(loss_or_val.item())\n",
    "\n",
    "mean_test_orpo = sum(test_orpo_list) / len(test_orpo_list)\n",
    "mean_test_sft = sum(test_sft_list) / len(test_sft_list)\n",
    "mean_test_or = sum(test_or_list) / len(test_or_list)\n",
    "\n",
    "print(f\"Test Results (with adapter):\")\n",
    "print(f\"ORPO Loss: {mean_test_orpo:.4f}\")\n",
    "print(f\"SFT Loss: {mean_test_sft:.4f}\")\n",
    "print(f\"OR Loss: {mean_test_or:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing without adapter (base model)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3a77e8492a4289b9bf860ed3dfe347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing without adapter:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results (without adapter):\n",
      "ORPO Loss: 14.3907\n",
      "SFT Loss: 7.3019\n",
      "OR Loss: 0.7089\n",
      "\n",
      "Improvement with adapter:\n",
      "ORPO Loss improvement: 0.7942\n",
      "SFT Loss improvement: -0.1381\n",
      "OR Loss improvement: 0.0932\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No adapter loaded. Please load an adapter first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 56\u001b[0m\n\u001b[1;32m     43\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/orpo_loss_with_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_test_orpo,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/loss_sft_with_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_test_sft,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/or_improvement\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_mean_test_or \u001b[38;5;241m-\u001b[39m mean_test_or,\n\u001b[1;32m     53\u001b[0m })\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Re-enable adapters for saving\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_adapters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Save adapters & finish\u001b[39;00m\n\u001b[1;32m     59\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(OUTPUT_DIR)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/integrations/peft.py:429\u001b[0m, in \u001b[0;36mPeftAdapterMixin.enable_adapters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m check_peft_version(min_version\u001b[38;5;241m=\u001b[39mMIN_PEFT_VERSION)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_peft_config_loaded:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo adapter loaded. Please load an adapter first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTunerLayer\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "\u001b[0;31mValueError\u001b[0m: No adapter loaded. Please load an adapter first."
     ]
    }
   ],
   "source": [
    "# Test without adapter (base model)\n",
    "print(\"\\nTesting without adapter (base model)...\")\n",
    "\n",
    "base_test_orpo_list, base_test_sft_list, base_test_or_list = [], [], []\n",
    "\n",
    "with torch.no_grad(), model.disable_adapter():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing without adapter\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(\n",
    "            model, prompt_inputs,\n",
    "            chosen_ids, chosen_mask,\n",
    "            rejected_ids, rejected_mask\n",
    "        )\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, rejected_logits,\n",
    "            chosen_ids, rejected_ids,\n",
    "            chosen_mask, rejected_mask,\n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "\n",
    "        base_test_orpo_list.append(loss_orpo_val.item())\n",
    "        base_test_sft_list.append(loss_sft_val.item())\n",
    "        base_test_or_list.append(loss_or_val.item())\n",
    "\n",
    "base_mean_test_orpo = sum(base_test_orpo_list) / len(base_test_orpo_list)\n",
    "base_mean_test_sft = sum(base_test_sft_list) / len(base_test_sft_list)\n",
    "base_mean_test_or = sum(base_test_or_list) / len(base_test_or_list)\n",
    "\n",
    "print(f\"Test Results (without adapter):\")\n",
    "print(f\"ORPO Loss: {base_mean_test_orpo:.4f}\")\n",
    "print(f\"SFT Loss: {base_mean_test_sft:.4f}\")\n",
    "print(f\"OR Loss: {base_mean_test_or:.4f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "print(f\"\\nImprovement with adapter:\")\n",
    "print(f\"ORPO Loss improvement: {base_mean_test_orpo - mean_test_orpo:.4f}\")\n",
    "print(f\"SFT Loss improvement: {base_mean_test_sft - mean_test_sft:.4f}\")\n",
    "print(f\"OR Loss improvement: {base_mean_test_or - mean_test_or:.4f}\")\n",
    "\n",
    "# Log results to wandb\n",
    "wandb.log({\n",
    "    \"test/orpo_loss_with_adapter\": mean_test_orpo,\n",
    "    \"test/loss_sft_with_adapter\": mean_test_sft,\n",
    "    \"test/loss_or_with_adapter\": mean_test_or,\n",
    "    \"test/orpo_loss_without_adapter\": base_mean_test_orpo,\n",
    "    \"test/loss_sft_without_adapter\": base_mean_test_sft,\n",
    "    \"test/loss_or_without_adapter\": base_mean_test_or,\n",
    "    \"test/orpo_improvement\": base_mean_test_orpo - mean_test_orpo,\n",
    "    \"test/sft_improvement\": base_mean_test_sft - mean_test_sft,\n",
    "    \"test/or_improvement\": base_mean_test_or - mean_test_or,\n",
    "})\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BD2hTAP7NllA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with adapter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8085dd0dff342409202c38e37d10b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing with adapter:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results (with adapter):\n",
      "ORPO Loss: 13.1854\n",
      "SFT Loss: 7.2381\n",
      "OR Loss: 0.5947\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "last_ckpt_dir = f\"{OUTPUT_DIR}/last\"\n",
    "model.load_adapter(last_ckpt_dir, adapter_name=\"last\")\n",
    "model.set_adapter(\"last\")\n",
    "\n",
    "# Test with adapter\n",
    "print(\"Testing with adapter...\")\n",
    "model.eval()\n",
    "test_orpo_list, test_sft_list, test_or_list = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing with adapter\"):\n",
    "        prompt_inputs, chosen_ids, chosen_mask, rejected_ids, rejected_mask = batch\n",
    "\n",
    "        chosen_logits, rejected_logits = answer_logits(\n",
    "            model, prompt_inputs,\n",
    "            chosen_ids, chosen_mask,\n",
    "            rejected_ids, rejected_mask\n",
    "        )\n",
    "\n",
    "        loss_orpo_val, loss_sft_val, loss_or_val = loss_orpo(\n",
    "            chosen_logits, rejected_logits,\n",
    "            chosen_ids, rejected_ids,\n",
    "            chosen_mask, rejected_mask,\n",
    "            ORPO_LAMBDA\n",
    "        )\n",
    "\n",
    "        test_orpo_list.append(loss_orpo_val.item())\n",
    "        test_sft_list.append(loss_sft_val.item())\n",
    "        test_or_list.append(loss_or_val.item())\n",
    "\n",
    "mean_test_orpo = sum(test_orpo_list) / len(test_orpo_list)\n",
    "mean_test_sft = sum(test_sft_list) / len(test_sft_list)\n",
    "mean_test_or = sum(test_or_list) / len(test_or_list)\n",
    "\n",
    "print(f\"Test Results (with adapter):\")\n",
    "print(f\"ORPO Loss: {mean_test_orpo:.4f}\")\n",
    "print(f\"SFT Loss: {mean_test_sft:.4f}\")\n",
    "print(f\"OR Loss: {mean_test_or:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMh8o9CVaj9ICPJkX1C/lN8",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "053400e801a4462795fa9e419ac5cb6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f07b87485f341879da1bbded82ca170",
      "max": 7482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45d21ebd5c6246b6ae556416b0f265f4",
      "value": 0
     }
    },
    "0bc34b4a59744eb0b83001fe470a6efb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5e68b2c41654c0a88f0a33d25c566ca",
       "IPY_MODEL_4eb4ff04a9154017819a2d8d91aa7594",
       "IPY_MODEL_db1e32da1e3c41d08001ee2f84fbdd20"
      ],
      "layout": "IPY_MODEL_b357a26e2974408f95ceff070ecdbbcb"
     }
    },
    "15c8ea12e1214f9e91e4cefa9f779f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15d0bfbe6dca4ab7b4f9232fca710300": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4524c55cb0434ff4b57fa375b4714221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7545b54978394866b1857651c60a697c",
      "placeholder": "​",
      "style": "IPY_MODEL_b14c52d996af42318011f89b94a4770e",
      "value": " 0/7482 [00:00&lt;?, ?it/s]"
     }
    },
    "45d21ebd5c6246b6ae556416b0f265f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4eb4ff04a9154017819a2d8d91aa7594": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15c8ea12e1214f9e91e4cefa9f779f39",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_632c2b5a95e744be9671406be88e68ae",
      "value": 4
     }
    },
    "60dfd26adca048c6927cb1c317701ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "632c2b5a95e744be9671406be88e68ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67f99b3f4e8e4757ad38c91d52e1611d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd86c15f1efc4c4c8f3572db97272742",
      "placeholder": "​",
      "style": "IPY_MODEL_fa2f5d1ddd174838a8816ba1d0643fa4",
      "value": "Epoch 1/1:   0%"
     }
    },
    "7545b54978394866b1857651c60a697c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ab1a9621b844f692943960d7fb1077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3166a5cd4d493298f52075284f2354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9729758f4b9c4410b8bc95e62cad67cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f99b3f4e8e4757ad38c91d52e1611d",
       "IPY_MODEL_053400e801a4462795fa9e419ac5cb6e",
       "IPY_MODEL_4524c55cb0434ff4b57fa375b4714221"
      ],
      "layout": "IPY_MODEL_15d0bfbe6dca4ab7b4f9232fca710300"
     }
    },
    "9f07b87485f341879da1bbded82ca170": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5e68b2c41654c0a88f0a33d25c566ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdffe38e72e14589b8e02c05a0f7d460",
      "placeholder": "​",
      "style": "IPY_MODEL_60dfd26adca048c6927cb1c317701ae9",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "b14c52d996af42318011f89b94a4770e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b357a26e2974408f95ceff070ecdbbcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd86c15f1efc4c4c8f3572db97272742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1e32da1e3c41d08001ee2f84fbdd20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b3166a5cd4d493298f52075284f2354",
      "placeholder": "​",
      "style": "IPY_MODEL_88ab1a9621b844f692943960d7fb1077",
      "value": " 4/4 [05:41&lt;00:00, 70.87s/it]"
     }
    },
    "fa2f5d1ddd174838a8816ba1d0643fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdffe38e72e14589b8e02c05a0f7d460": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
